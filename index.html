<!doctype html>
<html>
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>TYFYS Objection Coach</title>

<!-- Optional inline favicon -->
<link rel="icon" href='data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64"><rect width="64" height="64" rx="12" fill="%2300517a"/><text x="50%" y="55%" font-size="36" text-anchor="middle" fill="white" font-family="Arial">T</text></svg>'>

<style>
:root{
  --bg:#0b1a22;
  --panel:#122530;
  --muted:#8fb6c7;
  --text:#e6f2f7;
  --accent:#00b3ff;
  --accent-2:#34d399;
  --border:#1f3a47;
}
*{box-sizing:border-box}
body{background:var(--bg);color:var(--text);font-family:system-ui,-apple-system,Segoe UI,Roboto,Inter,Arial,sans-serif;max-width:980px;margin:24px auto;padding:0 16px}
h1{margin:8px 0 12px 0}
small{color:var(--muted)}
.k{background:var(--panel);border:1px solid var(--border);border-radius:14px;padding:14px;margin:10px 0}
textarea,input,button,select{width:100%;padding:12px;margin:8px 0;border-radius:12px;border:1px solid var(--border);background:var(--panel);color:var(--text)}
textarea::placeholder,input::placeholder{color:#89a8b6}
button{cursor:pointer;background:linear-gradient(90deg,var(--accent),#7dd3fc);font-weight:600;border:none}
button:disabled{opacity:.6;cursor:not-allowed}
select{appearance:none}
.row{display:grid;grid-template-columns:1fr 1fr;gap:12px}
.reply p{margin:0 0 10px 0;line-height:1.4}
.reply strong{display:inline-block;min-width:120px;color:var(--accent-2)}
ol{margin:8px 0 0 18px}
progress{width:100%}
.code{font-family:ui-monospace,Consolas,Menlo,monospace;font-size:12px;color:var(--muted)}
hr{border:0;border-top:1px solid var(--border);margin:10px 0}
</style>
</head>
<body>
<h1>TYFYS Objection Coach</h1>
<p><small>Paste a transcript snippet. Top matches come from your playbook. Reply is drafted by a small in-browser LLM.</small></p>

<div class="row k">
  <input id="pw" type="password" placeholder="Optional passphrase (leave blank to skip)" />
  <select id="model">
    <option value="Phi-3-mini-4k-instruct-q4f32_1-MLC" selected>Phi-3-Mini-Instruct (fast)</option>
    <option value="Llama-3.2-3B-Instruct-q4f32_1-MLC">Llama-3.2-3B-Instruct</option>
    <option value="Gemma-2-2B-it-q4f32_1-MLC">Gemma-2-2B-IT</option>
  </select>
</div>

<textarea id="snippet" rows="5" class="k" placeholder="Transcript snippet… e.g., I need to speak with my wife."></textarea>
<input id="tags" class="k" placeholder="Optional tags: vso, pricing, stall" />
<button id="go" class="k">Suggest reply</button>

<div id="status" class="k">
  <b>Status:</b> <span id="stat">Initializing…</span>
  <div id="progWrap" style="display:none;margin-top:8px">
    <progress id="prog" value="0" max="1"></progress>
    <div class="code"><span id="progText"></span></div>
  </div>
</div>

<div id="out" class="k"></div>
<div id="matches" class="k"></div>

<script type="module">
  // ---------- UI refs ----------
  const stat = document.getElementById('stat');
  const prog = document.getElementById('prog');
  const progWrap = document.getElementById('progWrap');
  const progText = document.getElementById('progText');
  const out = document.getElementById('out');
  const matchesDiv = document.getElementById('matches');
  const go = document.getElementById('go');
  const modelSel = document.getElementById('model');
  go.disabled = true;

  // ---------- Load playbook ----------
  let KB=[];
  try{
    const r=await fetch('objections.json',{cache:'no-store'});
    if(!r.ok) throw new Error('objections.json missing');
    KB = await r.json();
  }catch(e){
    stat.textContent='Error: '+e.message;
  }

  function score(snippet,tagsCsv,item){
    const s=(snippet||'').toLowerCase(); let sc=0;
    const text=[item.objection,item.rebuttal,item.proof].filter(Boolean).join(' ').toLowerCase();
    ['money','cost','fee','vso','dav','lawyer','risk','timeline','denied','rating','scam','family','wife','think','wait'].forEach(k=>{
      if(s.includes(k)&&text.includes(k)) sc+=2;
    });
    const obj=(item.objection||'').toLowerCase();
    if(obj && s.includes(obj.slice(0,18))) sc+=2;
    const want=new Set((tagsCsv||'').split(',').map(x=>x.trim().toLowerCase()).filter(Boolean));
    const have=new Set((item.tags||[]).map(x=>String(x).toLowerCase()));
    for(const t of want) if(have.has(t)) sc+=1;
    return sc;
  }
  function topK(snippet,tagsCsv,k=3){
    const arr=KB.map(x=>({item:x,s:score(snippet,tagsCsv,x)})).sort((a,b)=>b.s-a.s).slice(0,k).map(x=>x.item);
    return arr.length?arr:KB.slice(0,k);
  }

  // ---------- WebLLM ----------
  import * as webllm from "https://esm.run/@mlc-ai/web-llm";
  let engine=null;

  async function initEngine(modelName){
    stat.textContent=`Loading ${modelName}…`;
    progWrap.style.display='block'; prog.value=0; progText.textContent='';
    try{
      engine = await webllm.CreateMLCEngine(modelName,{
        gpuMemoryUtilization:0.7,
        initProgressCallback:(p)=>{
          if(p.text) progText.textContent=p.text;
          if(typeof p.progress==='number') prog.value=p.progress;
          if(p.error){ stat.textContent='Error: '+p.error; }
          if(p.progress===1){
            stat.textContent='Model ready.'; progWrap.style.display='none'; go.disabled=false;
          }
        }
      });
    }catch(e){
      stat.textContent='Engine init failed: '+e.message;
    }
  }

  await initEngine(modelSel.value);
  modelSel.onchange = async ()=>{ go.disabled=true; await initEngine(modelSel.value); };

  // ---------- Prompt ----------
  const SYS = `
You are a VA-disability objection coach for Thank You For Your Service (TYFYS).
Return HTML only in this exact structure:

<div class="reply">
  <p><strong>Acknowledge:</strong> <span>one concise sentence.</span></p>
  <p><strong>Clarify:</strong> <span>one focused question.</span></p>
  <p><strong>Offer:</strong></p>
  <ul>
    <li>Option A: <span>short, realistic step.</span></li>
    <li>Option B: <span>short alternative.</span></li>
  </ul>
</div>

No preambles or code fences. No legal advice. ≤120 words total. Write for spoken delivery.`;

  async function generate(snippet,matches){
    const ctx = matches.map(m=>`Objection: ${m.objection}\nBestReply: ${m.rebuttal}\nProof: ${m.proof||""}`).join("\n\n");
    const res = await engine.chat.completions.create({
      messages:[
        {role:"system",content:SYS},
        {role:"user",content:`Context:\n${ctx}\n\nTranscript:\n${snippet}\n\nCoach reply:`}
      ],
      temperature:0.5, max_tokens:220
    });
    return res.choices[0].message.content;
  }

  // ---------- Click ----------
  go.onclick = async ()=>{
    if(!engine){ out.textContent='Model still loading.'; return; }
    const pw=document.getElementById('pw').value.trim();
    if(pw && pw!=='TYFYS2025'){ out.textContent='Access denied.'; return; }
    const snippet=document.getElementById('snippet').value.trim();
    if(!snippet){ out.textContent='Enter a snippet.'; return; }
    const tags=document.getElementById('tags').value.trim();

    const picks=topK(snippet,tags,3);
    matchesDiv.innerHTML = `<b>Top matches</b><ol>`+
      picks.map(m=>`<li><b>${m.objection||'Untitled'}</b><br><small>${m.rebuttal||''}</small></li>`).join('')+
      `</ol>`;

    out.textContent='Thinking…';
    try{
      const html = await generate(snippet,picks);
      out.innerHTML = html; // render formatted sections
    }catch(e){
      out.textContent='AI error: '+e.message;
    }
  };
</script>
</body>
</html>
